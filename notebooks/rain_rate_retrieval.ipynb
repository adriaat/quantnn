{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GPROF rain rate retrieval\n",
    "\n",
    "In this notebook we will apply QRNNs to retrieve rain rates from passive microwave observations from the Global Precipitation Measurement (GPM) mission. We will then use the model to classify pixels based on their rain rate and compare the performance of the classifier to that of the current algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file training_data_gmi_small.nc.\n",
      "Downloading file test_data_gmi_small.nc.\n",
      "Downloading file validation_data_gmi_small.nc.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from quantnn.examples.gprof_simple import GPROFDataset, download_data\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The input data consists of single-pixel observations from the GMI radiometer combined with the surface type, column-integrated water vapor and two-meter temperature. Expanding the 14 surface types to one-hot encoding results in 29 input features.\n",
    "\n",
    "The output data consists of surface rain rates, which are, for the largest part, derived from GMI observations combined with the precipitation radar, which is flown together with GMI on board the GPM Core Observatory satellite. The combined radar-radiometer observations improve the accuracy of the rain retrieval, which is why this data is suitable to be used as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = GPROFDataset(\"data/training_data_gmi_small.nc\", batch_size=128)\n",
    "validation_data = GPROFDataset(\"data/training_data_gmi_small.nc\", batch_size=128, normalizer=training_data.normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "training_loader = DataLoader(training_data, batch_size=None, num_workers=2)\n",
    "validation_loader = DataLoader(validation_data, batch_size=None, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a QRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantnn as qn\n",
    "quantiles = [0.01, 0.05, 0.15, 0.25, 0.35, 0.45, 0.5, 0.55, 0.65, 0.75, 0.85, 0.95, 0.99]\n",
    "qrnn = qn.QRNN(n_inputs=29, quantiles=quantiles, model=(4, 256, \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the QRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                     Training history                     </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "                                                          \n",
       " <span style=\"font-weight: bold\">      Epoch      </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> \n",
       " ──────────────────────────────────────────────────────── \n",
       "     <span style=\"font-weight: bold\">#</span>      LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>        \n",
       "                                                          \n",
       "    <span style=\"font-weight: bold\">  1</span>   0.1000         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.020</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.018</span>        \n",
       "    <span style=\"font-weight: bold\">  2</span>   0.0976         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.018</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.018</span>        \n",
       "    <span style=\"font-weight: bold\">  3</span>   0.0905         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.017</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.017</span>        \n",
       "    <span style=\"font-weight: bold\">  4</span>   0.0794         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.017</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.016</span>        \n",
       "    <span style=\"font-weight: bold\">  5</span>   0.0655         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.016</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.016</span>        \n",
       "    <span style=\"font-weight: bold\">  6</span>   0.0500         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.016</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  7</span>   0.0345         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  8</span>   0.0206         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  9</span>   0.0095         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\"> 10</span>   0.0024         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                     Training history                     \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "                                                          \n",
       " \u001b[1m \u001b[0m\u001b[1m     Epoch     \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────── \n",
       "     \u001b[1m#\u001b[0m      LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m        \n",
       "                                                          \n",
       "    \u001b[1m  1\u001b[0m   0.1000         \u001b[1;31m0.020\u001b[0m               \u001b[1;34m0.018\u001b[0m        \n",
       "    \u001b[1m  2\u001b[0m   0.0976         \u001b[1;31m0.018\u001b[0m               \u001b[1;34m0.018\u001b[0m        \n",
       "    \u001b[1m  3\u001b[0m   0.0905         \u001b[1;31m0.017\u001b[0m               \u001b[1;34m0.017\u001b[0m        \n",
       "    \u001b[1m  4\u001b[0m   0.0794         \u001b[1;31m0.017\u001b[0m               \u001b[1;34m0.016\u001b[0m        \n",
       "    \u001b[1m  5\u001b[0m   0.0655         \u001b[1;31m0.016\u001b[0m               \u001b[1;34m0.016\u001b[0m        \n",
       "    \u001b[1m  6\u001b[0m   0.0500         \u001b[1;31m0.016\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  7\u001b[0m   0.0345         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  8\u001b[0m   0.0206         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  9\u001b[0m   0.0095         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m 10\u001b[0m   0.0024         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                     Training history                     </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "                                                          \n",
       " <span style=\"font-weight: bold\">      Epoch      </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> \n",
       " ──────────────────────────────────────────────────────── \n",
       "     <span style=\"font-weight: bold\">#</span>      LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>        \n",
       "                                                          \n",
       "    <span style=\"font-weight: bold\">  1</span>   0.0100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  2</span>   0.0098         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  3</span>   0.0090         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.015</span>        \n",
       "    <span style=\"font-weight: bold\">  4</span>   0.0079         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.015</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  5</span>   0.0065         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  6</span>   0.0050         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  7</span>   0.0035         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  8</span>   0.0021         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  9</span>   0.0010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\"> 10</span>   0.0002         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                     Training history                     \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "                                                          \n",
       " \u001b[1m \u001b[0m\u001b[1m     Epoch     \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────── \n",
       "     \u001b[1m#\u001b[0m      LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m        \n",
       "                                                          \n",
       "    \u001b[1m  1\u001b[0m   0.0100         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  2\u001b[0m   0.0098         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  3\u001b[0m   0.0090         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.015\u001b[0m        \n",
       "    \u001b[1m  4\u001b[0m   0.0079         \u001b[1;31m0.015\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  5\u001b[0m   0.0065         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  6\u001b[0m   0.0050         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  7\u001b[0m   0.0035         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  8\u001b[0m   0.0021         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  9\u001b[0m   0.0010         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m 10\u001b[0m   0.0002         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "<span style=\"font-style: italic\">                     Training history                     </span>\n",
       "<span style=\"font-style: italic\">                                                          </span>\n",
       "                                                          \n",
       " <span style=\"font-weight: bold\">      Epoch      </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> \n",
       " ──────────────────────────────────────────────────────── \n",
       "     <span style=\"font-weight: bold\">#</span>      LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>        \n",
       "                                                          \n",
       "    <span style=\"font-weight: bold\">  1</span>   0.0010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  2</span>   0.0010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  3</span>   0.0009         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  4</span>   0.0008         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  5</span>   0.0007         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  6</span>   0.0005         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  7</span>   0.0003         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  8</span>   0.0002         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\">  9</span>   0.0001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "    <span style=\"font-weight: bold\"> 10</span>   0.0000         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.014</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.014</span>        \n",
       "                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "\u001b[3m                     Training history                     \u001b[0m\n",
       "\u001b[3m                                                          \u001b[0m\n",
       "                                                          \n",
       " \u001b[1m \u001b[0m\u001b[1m     Epoch     \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────── \n",
       "     \u001b[1m#\u001b[0m      LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m        \n",
       "                                                          \n",
       "    \u001b[1m  1\u001b[0m   0.0010         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  2\u001b[0m   0.0010         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  3\u001b[0m   0.0009         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  4\u001b[0m   0.0008         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  5\u001b[0m   0.0007         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  6\u001b[0m   0.0005         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  7\u001b[0m   0.0003         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  8\u001b[0m   0.0002         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m  9\u001b[0m   0.0001         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "    \u001b[1m 10\u001b[0m   0.0000         \u001b[1;31m0.014\u001b[0m               \u001b[1;34m0.014\u001b[0m        \n",
       "                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "n_epochs = 10\n",
    "optimizer = torch.optim.SGD(qrnn.model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "qrnn.train(training_loader,\n",
    "           validation_loader,\n",
    "           optimizer=optimizer,\n",
    "           scheduler=scheduler,\n",
    "           n_epochs=n_epochs,\n",
    "           device=\"gpu\")\n",
    "optimizer = torch.optim.SGD(qrnn.model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "qrnn.train(training_loader,\n",
    "           validation_loader,\n",
    "           optimizer=optimizer,\n",
    "           scheduler=scheduler,\n",
    "           n_epochs=n_epochs,\n",
    "           device=\"gpu\")\n",
    "optimizer = torch.optim.SGD(qrnn.model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "qrnn.train(training_loader,\n",
    "           validation_loader,\n",
    "           optimizer=optimizer,\n",
    "           scheduler=scheduler,\n",
    "           n_epochs=n_epochs,\n",
    "           device=\"gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying raining pixels\n",
    "\n",
    "We will test our retrieval by using it to predict whether the rain rate at a given pixel is larger than a threshold of $0.01\\ \\text{mm/h}$. The estimated probability of a given pixel being larger than this value is also part of the GPROF retrieval output and we will use this output to evaluate the QRNN retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quantnn.examples.gprof_rr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6001e307c614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mquantnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgprof_rr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPROFTestset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPROFTestset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/test_data_gmi_small.nc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp_qrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability_larger_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp_gprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pop\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quantnn.examples.gprof_rr'"
     ]
    }
   ],
   "source": [
    "import quantnn as q\n",
    "from quantnn.examples.gprof_rr import GPROFTestset\n",
    "test_data = GPROFTestset(\"data/test_data_gmi_small.nc\", normalizer=training_data.normalizer)\n",
    "p_qrnn = qrnn.probability_larger_than(test_data.x, 0.01).detach().numpy()\n",
    "p_gprof = test_data.y_pop / 100.0\n",
    "truth = test_data.y.ravel() > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_and_recall_curve(p_pred, truth, n=101):\n",
    "    ps = np.linspace(0, 1, n)\n",
    "    precision = np.zeros(n)\n",
    "    recall = np.zeros(n)\n",
    "    for i, p in enumerate(ps):\n",
    "        predicted = p_pred > p\n",
    "        precision[i] = np.sum(predicted * truth) / np.sum(predicted)\n",
    "        recall[i] = np.sum(predicted * truth) / np.sum(truth)\n",
    "    return precision, recall\n",
    "\n",
    "precision_qrnn, recall_qrnn = precision_and_recall_curve(p_qrnn, truth)\n",
    "precision_gprof, recall_gprof = precision_and_recall_curve(p_gprof, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantnn.plotting import set_style\n",
    "set_style()\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(recall_qrnn, precision_qrnn, label=\"QRNN\")\n",
    "ax.plot(recall_gprof, precision_gprof, label=\"GPROF\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

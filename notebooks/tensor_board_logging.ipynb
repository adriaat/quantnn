{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19Ha8T2m-7yp"
   },
   "source": [
    "# Logging training progess using tensorboard\n",
    "\n",
    "quantnn now has some limited functionality to log training progress using [Tensorflow tensorboard](https://www.tensorflow.org/tensorboard/). This notebook provides an example how this functionality can be used using the convolutional rain rate retrieval form [this notebook](https://github.com/simonpf/quantnn/blob/main/notebooks/convolutional_rain_rate_retrieval.ipynb).\n",
    "\n",
    "> **Note**: This is still very new functionality so specific details of the API may change in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn.save(\"test.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = QRNN.load(\"test.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:          (epochs: 5)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1 2 3 4 5\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.05542 0.05283 0.05327 0.05314 0.05297\n",
       "    validation_loss  (epochs) float64 0.0465 0.04603 0.04699 0.04714 0.04699</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (epochs: 5)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1 2 3 4 5\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.05542 0.05283 0.05327 0.05314 0.05297\n",
       "    validation_loss  (epochs) float64 0.0465 0.04603 0.04699 0.04714 0.04699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "other.training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FpY9FNLU-7yy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"mathtext.fallback\" on line 203 in\n",
      "/home/simonpf/src/quantnn/quantnn/data/matplotlib_style.rc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from quantnn.plotting import set_style\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rSkQzbc-7yz"
   },
   "source": [
    "## Training setup\n",
    "\n",
    "To setup the example, we load the training and validation data and define a very simple convolutional network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4zhWXYUT-7y0"
   },
   "outputs": [],
   "source": [
    "from quantnn.examples.gprof_conv import download_data\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BqlD3XnD-7y1"
   },
   "outputs": [],
   "source": [
    "data = np.load(\"data/gprof_conv.npz\")\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_val = data[\"x_val\"]\n",
    "y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dzdtPg16-7y5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from quantnn.qrnn import QRNN\n",
    "\n",
    "quantiles = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "def make_nn_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(13, 128, 1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, 128, 1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, 128, 1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, quantiles.size, 1)\n",
    "    )\n",
    "\n",
    "model = make_nn_model()\n",
    "qrnn = QRNN(quantiles=quantiles, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate tensorboard logging\n",
    "\n",
    "Tensor board logging is activated by passing a ``quantnn.models.pytorch.logging.TensorBoardLogger`` object as the ``logger`` keyword argument to the QRNNs ``train`` method. \n",
    "\n",
    "The directory to which the logging data is written can be controlled using the ``log_directory`` argument passed to the ``TensorBoardLogger`` class upon initialization. If it is set to ``None``, logs for all experiments will be written into separate sub-folders in the ``run`` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRVE9em6-7y6",
    "outputId": "c5957d74-d71e-455c-f26b-38dc65c726cb",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                       </span>\n",
       "<span style=\"font-style: italic\">                                                       </span>\n",
       "<span style=\"font-style: italic\">                    Training history                   </span>\n",
       "<span style=\"font-style: italic\">                                                       </span>\n",
       "                                                       \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> \n",
       " ───────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>        \n",
       "                                                       \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.030</span>        \n",
       "                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                       \u001b[0m\n",
       "\u001b[3m                                                       \u001b[0m\n",
       "\u001b[3m                    Training history                   \u001b[0m\n",
       "\u001b[3m                                                       \u001b[0m\n",
       "                                                       \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR          \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m        \n",
       "                                                       \n",
       "   \u001b[1m  1\u001b[0m   0.010        \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.030\u001b[0m        \n",
       "                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from quantnn.models.pytorch import BatchedDataset\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "from torch.optim import Adam\n",
    "\n",
    "training_data = BatchedDataset((x_train, y_train), 4)\n",
    "validation_data = BatchedDataset((x_val, y_val), 4)\n",
    "n_epochs = 1\n",
    "\n",
    "# Set this explicitly \n",
    "log_directory = None\n",
    "logger = TensorBoardLogger(n_epochs,\n",
    "                           log_directory=log_directory)\n",
    "qrnn.train(training_data=training_data,\n",
    "           validation_data=validation_data,\n",
    "           n_epochs=n_epochs,\n",
    "           mask=-1,\n",
    "           device=\"gpu\",\n",
    "           logger=logger,\n",
    "           optimizer=Adam(qrnn.model.parameters(), lr=0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking validation metrics\n",
    "\n",
    "It is now also possible to track additional metrics over the validation set. So far, I have added mean squared error and bias of the posterior mean and the CRPS score. Additionally, I added two plot metrics, which produce plots of the calibration of the predicted quantiles and a scatter plot for the posterior mean.\n",
    "\n",
    "After training the `qrnn` object now also keeps an `training_history` attribute which is a `xarray.Dataset` that contains all tracked training statistics. This attribute is automatically saved with the QRNN, which should make it easier to keep track of the performance of different QRNNs.\n",
    "\n",
    "> **Note**: If you look at the calibration plots, you will see that they look terrible. The reason for that is the large number of 0s in the dataset. These cause the quantiles to be ill-defined for many predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                    Training history                                    </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "                                                                                        \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  MSE   </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Bias  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  CRPS  </span><span style=\"font-weight: bold\"> </span> \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>                                        \n",
       "                                                                                        \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.039</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.037</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.042   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.036  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.059   </span>  \n",
       "                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                    Training history                                    \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "                                                                                        \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m  Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  MSE   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m Bias  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  CRPS  \u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m                                        \n",
       "                                                                                        \n",
       "   \u001b[1m  1\u001b[0m   0.010         \u001b[1;31m0.039\u001b[0m               \u001b[1;34m0.037\u001b[0m         \u001b[38;5;129m0.042\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.036\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.059\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from quantnn.metrics import ScatterPlot\n",
    "\n",
    "# Metrics to be tracked can be defined either via their class name\n",
    "metrics = [\"MeanSquaredError\", \"Bias\", \"CRPS\", \"CalibrationPlot\"]\n",
    "# or by directly providing a metric object (If there are configuration parameters to set).\n",
    "scatter_plot = ScatterPlot(bins=np.logspace(-2, 2, 21), log_scale=True)\n",
    "metrics.append(scatter_plot)\n",
    "\n",
    "logger = TensorBoardLogger(n_epochs)\n",
    "qrnn.train(training_data=training_data,\n",
    "           validation_data=validation_data,\n",
    "           n_epochs=n_epochs,\n",
    "           mask=-1,\n",
    "           device=\"gpu\",\n",
    "           logger=logger,\n",
    "           metrics=metrics,\n",
    "           optimizer=Adam(qrnn.model.parameters(), lr=0.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:          (epochs: 1)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.03949\n",
       "    validation_loss  (epochs) float64 0.03658\n",
       "    MSE              (epochs) float32 0.04240294\n",
       "    Bias             (epochs) float32 0.035960514\n",
       "    CRPS             (epochs) float32 0.05905865</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (epochs: 1)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.03949\n",
       "    validation_loss  (epochs) float64 0.03658\n",
       "    MSE              (epochs) float32 0.04240294\n",
       "    Bias             (epochs) float32 0.035960514\n",
       "    CRPS             (epochs) float32 0.05905865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrnn.training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping track of hyperparameters\n",
    "\n",
    "To keep track of hyperparameters, the logger now as an additional method ``set_attributes`` that allows you to pass a ``dict`` containing numerical values and strings that will be stored in the tensor board as well as the attributes field of the QRNNs training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                    Training history                                    </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "                                                                                        \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  MSE   </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Bias  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  CRPS  </span><span style=\"font-weight: bold\"> </span> \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>                                        \n",
       "                                                                                        \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.064</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.051</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.044   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.038  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.122   </span>  \n",
       "   <span style=\"font-weight: bold\">  2</span>   0.100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.057</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.052</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.044   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.038  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.069   </span>  \n",
       "   <span style=\"font-weight: bold\">  3</span>   0.100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.056</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.050</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.044   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.038  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.089   </span>  \n",
       "   <span style=\"font-weight: bold\">  4</span>   0.100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.057</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.050</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.046   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.039  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.108   </span>  \n",
       "   <span style=\"font-weight: bold\">  5</span>   0.100         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.057</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.050</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.044   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.098   </span>  \n",
       "                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                    Training history                                    \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "                                                                                        \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m  Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  MSE   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m Bias  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  CRPS  \u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m                                        \n",
       "                                                                                        \n",
       "   \u001b[1m  1\u001b[0m   0.100         \u001b[1;31m0.064\u001b[0m               \u001b[1;34m0.051\u001b[0m         \u001b[38;5;129m0.044\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.038\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.122\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  2\u001b[0m   0.100         \u001b[1;31m0.057\u001b[0m               \u001b[1;34m0.052\u001b[0m         \u001b[38;5;129m0.044\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.038\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.069\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  3\u001b[0m   0.100         \u001b[1;31m0.056\u001b[0m               \u001b[1;34m0.050\u001b[0m         \u001b[38;5;129m0.044\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.038\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.089\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  4\u001b[0m   0.100         \u001b[1;31m0.057\u001b[0m               \u001b[1;34m0.050\u001b[0m         \u001b[38;5;129m0.046\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.039\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.108\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  5\u001b[0m   0.100         \u001b[1;31m0.057\u001b[0m               \u001b[1;34m0.050\u001b[0m         \u001b[38;5;129m0.044\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.098\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                    Training history                                    </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "                                                                                        \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  MSE   </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Bias  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  CRPS  </span><span style=\"font-weight: bold\"> </span> \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>                                        \n",
       "                                                                                        \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.054</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.034</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.048   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.038  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.062   </span>  \n",
       "   <span style=\"font-weight: bold\">  2</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.040</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.032</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.046   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.043   </span>  \n",
       "   <span style=\"font-weight: bold\">  3</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.038</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.029</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.054   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.038  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.056   </span>  \n",
       "   <span style=\"font-weight: bold\">  4</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.036</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.030</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.046   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.050   </span>  \n",
       "   <span style=\"font-weight: bold\">  5</span>   0.010         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.036</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.028</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.048   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.050   </span>  \n",
       "                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                    Training history                                    \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "                                                                                        \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m  Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  MSE   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m Bias  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  CRPS  \u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m                                        \n",
       "                                                                                        \n",
       "   \u001b[1m  1\u001b[0m   0.010         \u001b[1;31m0.054\u001b[0m               \u001b[1;34m0.034\u001b[0m         \u001b[38;5;129m0.048\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.038\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.062\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  2\u001b[0m   0.010         \u001b[1;31m0.040\u001b[0m               \u001b[1;34m0.032\u001b[0m         \u001b[38;5;129m0.046\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.043\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  3\u001b[0m   0.010         \u001b[1;31m0.038\u001b[0m               \u001b[1;34m0.029\u001b[0m         \u001b[38;5;129m0.054\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.038\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.056\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  4\u001b[0m   0.010         \u001b[1;31m0.036\u001b[0m               \u001b[1;34m0.030\u001b[0m         \u001b[38;5;129m0.046\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.050\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  5\u001b[0m   0.010         \u001b[1;31m0.036\u001b[0m               \u001b[1;34m0.028\u001b[0m         \u001b[38;5;129m0.048\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.050\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "<span style=\"font-style: italic\">                                    Training history                                    </span>\n",
       "<span style=\"font-style: italic\">                                                                                        </span>\n",
       "                                                                                        \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  MSE   </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Bias  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  CRPS  </span><span style=\"font-weight: bold\"> </span> \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR           <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>                                        \n",
       "                                                                                        \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.035</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.052   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.039  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.034  </span>  \n",
       "   <span style=\"font-weight: bold\">  2</span>   0.001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.042</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.032</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.046   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037   </span>  \n",
       "   <span style=\"font-weight: bold\">  3</span>   0.001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.041</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.031</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.046   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.047   </span>  \n",
       "   <span style=\"font-weight: bold\">  4</span>   0.001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.041</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.032</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.052   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.039  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.042   </span>  \n",
       "   <span style=\"font-weight: bold\">  5</span>   0.001         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.040</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.031</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.045   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.037   </span>  \n",
       "                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "\u001b[3m                                    Training history                                    \u001b[0m\n",
       "\u001b[3m                                                                                        \u001b[0m\n",
       "                                                                                        \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m  Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  MSE   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m Bias  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  CRPS  \u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR           \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m                                        \n",
       "                                                                                        \n",
       "   \u001b[1m  1\u001b[0m   0.001         \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.035\u001b[0m         \u001b[38;5;129m0.052\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.039\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m-0.034\u001b[0m\u001b[38;5;129m  \u001b[0m  \n",
       "   \u001b[1m  2\u001b[0m   0.001         \u001b[1;31m0.042\u001b[0m               \u001b[1;34m0.032\u001b[0m         \u001b[38;5;129m0.046\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  3\u001b[0m   0.001         \u001b[1;31m0.041\u001b[0m               \u001b[1;34m0.031\u001b[0m         \u001b[38;5;129m0.046\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.047\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  4\u001b[0m   0.001         \u001b[1;31m0.041\u001b[0m               \u001b[1;34m0.032\u001b[0m         \u001b[38;5;129m0.052\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.039\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.042\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "   \u001b[1m  5\u001b[0m   0.001         \u001b[1;31m0.040\u001b[0m               \u001b[1;34m0.031\u001b[0m         \u001b[38;5;129m0.045\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.037\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics to be tracked can be defined either via their class name\n",
    "metrics = [\"MeanSquaredError\", \"Bias\", \"CRPS\", \"CalibrationPlot\"]\n",
    "# or by directly providing a metric object (If there are configuration parameters to set).\n",
    "scatter_plot = ScatterPlot(bins=np.logspace(-2, 2, 21), log_scale=True)\n",
    "metrics.append(scatter_plot)\n",
    "\n",
    "\n",
    "for lr in [1e-1, 1e-2, 1e-3]:\n",
    "    # Use new model for each training.\n",
    "    qrnn.model = make_nn_model()\n",
    "    \n",
    "    # Log hyperparameters.\n",
    "    logger = TensorBoardLogger(n_epochs)\n",
    "    logger.set_attributes({\"optimizer\": \"Adam\", \"learning_rate\": lr})\n",
    "    \n",
    "    optimizer = Adam(qrnn.model.parameters(), lr=lr)\n",
    "    \n",
    "    qrnn.train(training_data=training_data,\n",
    "               validation_data=validation_data,\n",
    "               n_epochs=5,\n",
    "               mask=-1,\n",
    "               device=\"gpu\",\n",
    "               logger=logger,\n",
    "               metrics=metrics,\n",
    "               optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:          (epochs: 5)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1 2 3 4 5\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.05308 0.04227 0.04082 0.04117 0.04027\n",
       "    validation_loss  (epochs) float64 0.03537 0.03187 0.03136 0.03248 0.0312\n",
       "    MSE              (epochs) float32 0.052078348 0.04617617 ... 0.04540595\n",
       "    Bias             (epochs) float32 0.039082687 0.03693702 ... 0.036758274\n",
       "    CRPS             (epochs) float32 -0.034470726 0.0374144 ... 0.03670201</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (epochs: 5)\n",
       "Coordinates:\n",
       "  * epochs           (epochs) int64 1 2 3 4 5\n",
       "Data variables:\n",
       "    training_loss    (epochs) float64 0.05308 0.04227 0.04082 0.04117 0.04027\n",
       "    validation_loss  (epochs) float64 0.03537 0.03187 0.03136 0.03248 0.0312\n",
       "    MSE              (epochs) float32 0.052078348 0.04617617 ... 0.04540595\n",
       "    Bias             (epochs) float32 0.039082687 0.03693702 ... 0.036758274\n",
       "    CRPS             (epochs) float32 -0.034470726 0.0374144 ... 0.03670201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrnn.training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUVKdn8w-7y6"
   },
   "source": [
    "## Tracking progress on a specific input\n",
    "\n",
    "By default, the tensor board logger will log only training and validaiton error. Custom data can be logged using a callback hook (defined by the ``epoch_begin_callback`` attributed of the ``TensorBoardLogger`` class) that is called at the beginning of each epoch.\n",
    "\n",
    "\n",
    "The ``epoch_begin_callback`` is expected to have the following signature:\n",
    "\n",
    "\n",
    "````python\n",
    "def epoch_begin_callback(model, writer, epoch_index):\n",
    "````\n",
    "where the arguments correspond to the following\n",
    "- ``model``: The PyTorch model that is trained in its current state.\n",
    "- ``writer``: The  [SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html)  that is used to log data for the current training session.\n",
    "                \n",
    "- ``epoch_index``: The index (zero-based) of the current epoch.\n",
    "        \n",
    "The example below illustrates how this functionality can be used to track the prediction on a specific input at the beginning of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_val[:1]\n",
    "y = y_val[:1]\n",
    "\n",
    "def make_prediction(writer, model, epoch_index):\n",
    "    \"\"\"\n",
    "    Predicts the mean precipitation rate on the first sample\n",
    "    from the validation set.\n",
    "    \n",
    "    Args:\n",
    "        writer: The SummaryWriter object that is used to log\n",
    "             to the tensbor board.\n",
    "        model: The model attributed of the qrnn object being\n",
    "            trained.\n",
    "        epoch_index: The index (zero-based) of the current\n",
    "            epoch.\n",
    "    \"\"\"\n",
    "    # Make prediction\n",
    "    y_mean = qrnn.posterior_mean(x)\n",
    "    # Store output using add_image function of SummaryWriter\n",
    "    writer.add_image(\"predicted_rain_rate\", y_mean, epoch_index)\n",
    "    \n",
    "    # Store reference imager using add_image function of\n",
    "    # SummaryWriter. No need to store for every epoch.\n",
    "    writer.add_image(\"reference_rain_rate\", y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                       </span>\n",
       "<span style=\"font-style: italic\">                                                       </span>\n",
       "<span style=\"font-style: italic\">                    Training history                   </span>\n",
       "<span style=\"font-style: italic\">                                                       </span>\n",
       "                                                       \n",
       " <span style=\"font-weight: bold\">    Epoch     </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> \n",
       " ───────────────────────────────────────────────────── \n",
       "    <span style=\"font-weight: bold\">#</span>     LR          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>        \n",
       "                                                       \n",
       "   <span style=\"font-weight: bold\">  1</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.055</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.047</span>        \n",
       "   <span style=\"font-weight: bold\">  2</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.046</span>        \n",
       "   <span style=\"font-weight: bold\">  3</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.047</span>        \n",
       "   <span style=\"font-weight: bold\">  4</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.047</span>        \n",
       "   <span style=\"font-weight: bold\">  5</span>   0.010        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.053</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.047</span>        \n",
       "                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                       \u001b[0m\n",
       "\u001b[3m                                                       \u001b[0m\n",
       "\u001b[3m                    Training history                   \u001b[0m\n",
       "\u001b[3m                                                       \u001b[0m\n",
       "                                                       \n",
       " \u001b[1m \u001b[0m\u001b[1m   Epoch    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────────────────── \n",
       "    \u001b[1m#\u001b[0m     LR          \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m        \n",
       "                                                       \n",
       "   \u001b[1m  1\u001b[0m   0.010        \u001b[1;31m0.055\u001b[0m               \u001b[1;34m0.047\u001b[0m        \n",
       "   \u001b[1m  2\u001b[0m   0.010        \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.046\u001b[0m        \n",
       "   \u001b[1m  3\u001b[0m   0.010        \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.047\u001b[0m        \n",
       "   \u001b[1m  4\u001b[0m   0.010        \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.047\u001b[0m        \n",
       "   \u001b[1m  5\u001b[0m   0.010        \u001b[1;31m0.053\u001b[0m               \u001b[1;34m0.047\u001b[0m        \n",
       "                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from quantnn.models.pytorch import BatchedDataset\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "\n",
    "\n",
    "training_data = BatchedDataset((x_train, y_train), 4)\n",
    "validation_data = BatchedDataset((x_val, y_val), 4)\n",
    "n_epochs = 5\n",
    "logger = TensorBoardLogger(n_epochs,\n",
    "                           log_directory=None,\n",
    "                           epoch_begin_callback=make_prediction)\n",
    "qrnn.train(training_data=training_data,\n",
    "           validation_data=validation_data,\n",
    "           n_epochs=n_epochs,\n",
    "           mask=-1,\n",
    "           device=\"gpu\",\n",
    "              logger=logger);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "convolutional_rain_rate_retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
